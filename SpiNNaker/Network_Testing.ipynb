{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spynnaker8 as p\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import spynnaker8.spynnaker_plotting as pl\n",
    "import spynnaker8.utilities.neo_convertor as convert\n",
    "from pyNN.utility.plotting import Figure, Panel\n",
    "import os\n",
    "import csv\n",
    "import openpyxl\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving into the directory which contains the batch files\n",
    "os.chdir(\"/home/jovyan/SpeechRecognition/Weights_Graph_and_testing/CSV_files\") #Create a batch folder \n",
    "file_name = \"all_csvs_1.xlsx\"\n",
    "\n",
    "\n",
    "list_to_append_1 = []\n",
    "\n",
    "book = openpyxl.load_workbook(file_name)\n",
    "sheet = book.active\n",
    "row_count = sheet.max_row\n",
    "col_count = sheet.max_column\n",
    "\n",
    "for j in range(2,row_count+1):\n",
    "    list_of_data = []\n",
    "    for k in range(2,col_count+1):\n",
    "        list_of_data.append(sheet.cell(row=j, column=k).value)\n",
    "    list_to_append_1.append(list_of_data)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#Moving into the directory which contains the batch files\n",
    "os.chdir(\"/home/jovyan/SpeechRecognition/Weights_Graph_and_testing/CSV_files\") #Create a batch folder \n",
    "file_name = \"all_csvs_0.xlsx\"\n",
    "\n",
    "\n",
    "list_to_append_0 = []\n",
    "\n",
    "book = openpyxl.load_workbook(file_name)\n",
    "sheet = book.active\n",
    "row_count = sheet.max_row\n",
    "col_count = sheet.max_column\n",
    "\n",
    "for j in range(2,row_count+1):\n",
    "    list_of_data = []\n",
    "    for k in range(2,col_count+1):\n",
    "        list_of_data.append(sheet.cell(row=j, column=k).value)\n",
    "    list_to_append_0.append(list_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_to_append_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_to_append_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_to_append_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_to_append_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []\n",
    "training_label = []\n",
    "\n",
    "for i in range(50):\n",
    "    training_list.append(list_to_append_0[i])\n",
    "    training_label.append(0)\n",
    "    \n",
    "for i in range(3):\n",
    "    training_list.append(list_to_append_1[i])\n",
    "    training_label.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(training_list, training_label)) \n",
    "random.shuffle(temp) \n",
    "training_list, training_label = zip(*temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK FOR TRAINING \n",
    "list_of_weights = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "TotalDuration = 1000.0\n",
    "\n",
    "weights_list = []\n",
    "\n",
    "#initialising random weights for the first iteration\n",
    "for i in range(10):\n",
    "    weights = []\n",
    "    for j in range(200):\n",
    "        weights.append(random.uniform(0.001,0.01))\n",
    "    weights_list.append(weights)\n",
    "\n",
    "list_of_weights.append(weights_list)    \n",
    "\n",
    "# yet to take weights and feed it to the network for the next feature vector\n",
    "for i,feature in enumerate(training_list):\n",
    "    \n",
    "    NumYCells = 200\n",
    "    NumZCells = 1\n",
    "    \n",
    "    correct_digit = training_label[i]\n",
    "\n",
    "    #defining conductance based Izhikevich model\n",
    "    model_Izh = p.extra_models.Izhikevich_cond\n",
    "\n",
    "    snr_a=0.02 #0.005\n",
    "    snr_b=0.2 #0.32\n",
    "    snr_c=-65 #-65\n",
    "    snr_d=8 #2\n",
    "    snr_v_init = 30 #-70\n",
    "    snr_u_init = -13 #snr_b * snr_v_init\n",
    "\n",
    "    tau_ampa = 6###excitatory synapse time constant\n",
    "    tau_gabaa= 4### inhibitory synapse time constant\n",
    "    E_ampa = 0.0\n",
    "    E_gabaa = -80.0\n",
    "    current_bias = -2.\n",
    "    cell_params_input = {'a': snr_a, 'b': snr_b, 'c': snr_c, 'd': snr_d,\n",
    "                       'v': snr_v_init, 'u': snr_u_init,\n",
    "                       'tau_syn_E': tau_ampa, 'tau_syn_I': tau_gabaa,\n",
    "                       'i_offset': feature,\n",
    "                       'e_rev_E': E_ampa, 'e_rev_I': E_gabaa,\n",
    "                       }\n",
    "    cell_params_output_target = {'a': snr_a, 'b': snr_b, 'c': snr_c, 'd': snr_d,\n",
    "                       'v': snr_v_init, 'u': snr_u_init,\n",
    "                       'tau_syn_E': tau_ampa, 'tau_syn_I': tau_gabaa,\n",
    "                       'i_offset': sum(feature)/len(feature),\n",
    "                       'e_rev_E': E_ampa, 'e_rev_I': E_gabaa,\n",
    "                       }\n",
    "    cell_params_output = {'a': snr_a, 'b': snr_b, 'c': snr_c, 'd': snr_d,\n",
    "                       'v': snr_v_init, 'u': snr_u_init,\n",
    "                       'tau_syn_E': tau_ampa, 'tau_syn_I': tau_gabaa,\n",
    "                       'i_offset': -3.0,\n",
    "                       'e_rev_E': E_ampa, 'e_rev_I': E_gabaa,\n",
    "                       }\n",
    "\n",
    "\n",
    "    p.setup(timestep=0.1, min_delay=1.0, max_delay=1.0)\n",
    "    \n",
    "    z_population = []\n",
    "\n",
    "\n",
    "    #input population of 200\n",
    "    y_population = p.Population(NumYCells, model_Izh(**cell_params_input), label='RS_Izh_neuron_input')\n",
    "\n",
    "    #output population of 10\n",
    "    for j in range(10):\n",
    "        if j==correct_digit:\n",
    "            z_population.append(p.Population(NumZCells, model_Izh(**cell_params_output_target), label='RS_Izh_neuron_output_target'))\n",
    "        else:\n",
    "            z_population.append(p.Population(NumZCells, model_Izh(**cell_params_output), label='RS_Izh_neuron_output'))\n",
    "\n",
    "    ee_connector = p.AllToAllConnector()\n",
    "\n",
    "\n",
    "    stdp_projection = []\n",
    "\n",
    "    for j in range(10):\n",
    "        \n",
    "        if j==correct_digit: #if correct digit\n",
    "            #defining Hebbian learning rule \n",
    "            timing_rule = p.SpikePairRule(tau_plus=20.,tau_minus=20.,A_plus=0.02,A_minus=0.02)\n",
    "        else:\n",
    "            #defining Anti-Hebbian learning rule\n",
    "            timing_rule = p.SpikePairRuleAntiHebbian(tau_plus=20.,tau_minus=20.,A_plus=0.02,A_minus=0.02)\n",
    "\n",
    "        #defining the STDP learning rule with the required parameters\n",
    "        stdp_model = p.STDPMechanism(timing_dependence=timing_rule,weight_dependence=p.AdditiveWeightDependence(w_min=0.001,w_max=0.01),weight=weights_list[j],delay=0.1) #MultiplicativeWeightDependence, add appropriate weight range: 0.001 to 0.01\n",
    "        stdp_projection.append(p.Projection(y_population,z_population[j],ee_connector,synapse_type=stdp_model))\n",
    "\n",
    "    #simulation and results\n",
    "    y_population.record(['v', 'spikes'])\n",
    "    z_population[0].record(['v', 'spikes'])\n",
    "    z_population[1].record(['v', 'spikes'])\n",
    "    z_population[2].record(['v', 'spikes'])\n",
    "    z_population[3].record(['v', 'spikes'])\n",
    "    z_population[4].record(['v', 'spikes'])\n",
    "    z_population[5].record(['v', 'spikes'])\n",
    "    z_population[6].record(['v', 'spikes'])\n",
    "    z_population[7].record(['v', 'spikes'])\n",
    "    z_population[8].record(['v', 'spikes'])\n",
    "    z_population[9].record(['v', 'spikes'])\n",
    "\n",
    "    p.run(TotalDuration)\n",
    "\n",
    "    #redifine weights_list to get new values so that they can be used in the next iteration\n",
    "    weights_list = []\n",
    "    for i in range(len(stdp_projection)):\n",
    "        print(\"Weights:{}\".format(stdp_projection[i].get('weight', 'list')))\n",
    "        weights = stdp_projection[i].get('weight', 'list')\n",
    "        weight_list = []\n",
    "        for j in range(len(weights)):\n",
    "            weight_list.append(weights[j][2])\n",
    "        weights_list.append(weight_list)\n",
    "        \n",
    "        \n",
    "    list_of_weights.append(weights_list)\n",
    "    \n",
    "    \n",
    "    pre_spikes = y_population.get_data('spikes')\n",
    "    post_spikes = []\n",
    "    for i in range(10):\n",
    "        post_spikes.append(z_population[i].get_data('spikes'))\n",
    "        \n",
    "    # post_spikes = z_population[0].get_data('spikes')\n",
    "\n",
    "#     Figure(Panel(pre_spikes.segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[0].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[1].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[2].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[3].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[4].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[5].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[6].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[7].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[8].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[9].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), title=\"Speech Classifier\", annotations=\"simulated with {}\".format(p.name())).save('SpeechClassification.png')\n",
    "\n",
    "    # Figure(Panel(pre_spikes.segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)), Panel(post_spikes[0].segments[0].spiketrains, yticks=True, markersize=0.2, xlim=(0,TotalDuration)))\n",
    "\n",
    "    p.end()  \n",
    "    \n",
    "    print(\"**************************************************\")\n",
    "    print(weights_list)\n",
    "    print(\"**************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time = 0.0\n",
    "list_of_timesteps = []\n",
    "for i in range(len(training_list)):\n",
    "    time+=1000.0\n",
    "    list_of_timesteps.append(time)\n",
    "    \n",
    "synapse_0 = []\n",
    "synapse_1 = []\n",
    "synapse_2 = []\n",
    "synapse_3 = []\n",
    "synapse_4 = []\n",
    "synapse_5 = []\n",
    "synapse_6 = []\n",
    "synapse_7 = []\n",
    "synapse_8 = []\n",
    "synapse_9 = []\n",
    "\n",
    "for i in range(len(list_of_weights[1:])):\n",
    "    for j in range(len(list_of_weights[i])):\n",
    "        if j==0:\n",
    "            synapse_0.append(list_of_weights[i][j])\n",
    "        elif j==1:\n",
    "            synapse_1.append(list_of_weights[i][j])\n",
    "        elif j==2:\n",
    "            synapse_2.append(list_of_weights[i][j])\n",
    "        elif j==3:\n",
    "            synapse_3.append(list_of_weights[i][j])\n",
    "        elif j==4:\n",
    "            synapse_4.append(list_of_weights[i][j])\n",
    "        elif j==5:\n",
    "            synapse_5.append(list_of_weights[i][j])\n",
    "        elif j==6:\n",
    "            synapse_6.append(list_of_weights[i][j])\n",
    "        elif j==7:\n",
    "            synapse_7.append(list_of_weights[i][j])\n",
    "        elif j==8:\n",
    "            synapse_8.append(list_of_weights[i][j])\n",
    "        elif j==9:\n",
    "            synapse_9.append(list_of_weights[i][j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synapse_0_0 = []\n",
    "for i in range(len(synapse_0)):\n",
    "#     print(len(synapse_0[i]))\n",
    "    synapse_0_0.append(synapse_0[i][199])\n",
    "    \n",
    "synapse_1_0 = []\n",
    "for i in range(len(synapse_1)):\n",
    "    synapse_1_0.append(synapse_1[i][0])\n",
    "    \n",
    "plt.xlabel('Simulation Time Steps')\n",
    "plt.ylabel('Weights associated with 0th output neuron')\n",
    "# plt.plot(list_of_timesteps, synapse_0_0, 'ro')\n",
    "plt.plot(synapse_0,'ro')\n",
    "plt.show()\n",
    "plt.savefig('Time_vs_Weights_Synapse_0_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(post_spikes[2].segments[0].spiketrains[0])\n",
    "\n",
    "# if post_spikes[0].segments[0].spiketrains[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_list = []\n",
    "testing_label = []\n",
    "\n",
    "# testing_list.append(list_to_append_0[30])\n",
    "# testing_label.append(0)\n",
    "\n",
    "for i in range(21,29):\n",
    "    testing_list.append(list_to_append_0[i])\n",
    "    testing_label.append(0)\n",
    "    \n",
    "for i in range(6,8):\n",
    "    testing_list.append(list_to_append_1[i])\n",
    "    testing_label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(testing_list)\n",
    "num_correct = 0\n",
    "\n",
    "# yet to take weights and feed it to the network for the next feature vector\n",
    "for i,feature in enumerate(testing_list):\n",
    "    \n",
    "    NumYCells = 200\n",
    "    NumZCells = 1\n",
    "    \n",
    "    correct_digit = testing_label[i]\n",
    "\n",
    "    #defining conductance based Izhikevich model\n",
    "    model_Izh = p.extra_models.Izhikevich_cond\n",
    "\n",
    "    snr_a=0.02 #0.005\n",
    "    snr_b=0.2 #0.32\n",
    "    snr_c=-65 #-65\n",
    "    snr_d=8 #2\n",
    "    snr_v_init = 30 #-70\n",
    "    snr_u_init = -13 #snr_b * snr_v_init\n",
    "\n",
    "    tau_ampa = 6###excitatory synapse time constant\n",
    "    tau_gabaa= 4### inhibitory synapse time constant\n",
    "    E_ampa = 0.0\n",
    "    E_gabaa = -80.0\n",
    "    current_bias = -2.\n",
    "    cell_params_input = {'a': snr_a, 'b': snr_b, 'c': snr_c, 'd': snr_d,\n",
    "                       'v': snr_v_init, 'u': snr_u_init,\n",
    "                       'tau_syn_E': tau_ampa, 'tau_syn_I': tau_gabaa,\n",
    "                       'i_offset': feature,\n",
    "                       'e_rev_E': E_ampa, 'e_rev_I': E_gabaa,\n",
    "                       }\n",
    "    cell_params_output = {'a': snr_a, 'b': snr_b, 'c': snr_c, 'd': snr_d,\n",
    "                       'v': snr_v_init, 'u': snr_u_init,\n",
    "                       'tau_syn_E': tau_ampa, 'tau_syn_I': tau_gabaa,\n",
    "                       'i_offset': 0.0,\n",
    "                       'e_rev_E': E_ampa, 'e_rev_I': E_gabaa,\n",
    "                       }\n",
    "\n",
    "\n",
    "    p.setup(timestep=0.1, min_delay=1.0, max_delay=1.0)\n",
    "    \n",
    "    z_population = []\n",
    "\n",
    "\n",
    "    #input population of 200\n",
    "    y_population = p.Population(NumYCells, model_Izh(**cell_params_input), label='RS_Izh_neuron_input')\n",
    "\n",
    "    #output population of 10\n",
    "    for j in range(10):\n",
    "        z_population.append(p.Population(NumZCells, model_Izh(**cell_params_output), label='RS_Izh_neuron_output'))\n",
    "\n",
    "    ee_connector = p.AllToAllConnector()\n",
    "\n",
    "    for j in range(10):\n",
    "        wiring = p.AllToAllConnector()\n",
    "        static_synapse = p.StaticSynapse(weight=weights_list[j], delay=0.1)\n",
    "        connections = p.Projection(y_population, z_population[i], wiring, static_synapse)\n",
    "        \n",
    "\n",
    "    #simulation and results\n",
    "    y_population.record(['v', 'spikes'])\n",
    "    z_population[0].record(['v', 'spikes'])\n",
    "    z_population[1].record(['v', 'spikes'])\n",
    "    z_population[2].record(['v', 'spikes'])\n",
    "    z_population[3].record(['v', 'spikes'])\n",
    "    z_population[4].record(['v', 'spikes'])\n",
    "    z_population[5].record(['v', 'spikes'])\n",
    "    z_population[6].record(['v', 'spikes'])\n",
    "    z_population[7].record(['v', 'spikes'])\n",
    "    z_population[8].record(['v', 'spikes'])\n",
    "    z_population[9].record(['v', 'spikes'])\n",
    "\n",
    "    p.run(TotalDuration)\n",
    "    \n",
    "    \n",
    "    pre_spikes = y_population.get_data('spikes')\n",
    "    post_spikes = []\n",
    "    for i in range(10):\n",
    "        post_spikes.append(z_population[i].get_data('spikes'))\n",
    "    \n",
    "    index = -1\n",
    "    max_num = 0\n",
    "    for j in range(10):\n",
    "        print(len(post_spikes[j].segments[0].spiketrains[0]))\n",
    "        if len(post_spikes[j].segments[0].spiketrains[0])>max_num:\n",
    "            max_num = len(post_spikes[j].segments[0].spiketrains[0])\n",
    "            index = j\n",
    "            \n",
    "    print(\"Actual digit:\")\n",
    "    print(correct_digit)\n",
    "    print(\"Predicted digit:\")\n",
    "    print(index)\n",
    "    \n",
    "    if correct_digit == index:\n",
    "        num_correct+=1\n",
    "        \n",
    "    p.end()  \n",
    "\n",
    "print(\"Total number of samples:\")\n",
    "print(total_num)\n",
    "print(\"Number of samples correctly predicted:\")\n",
    "print(num_correct)\n",
    "print(\"Accuracy:\")\n",
    "print(num_correct/total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNakerGit",
   "language": "python",
   "name": "spynnakergit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
